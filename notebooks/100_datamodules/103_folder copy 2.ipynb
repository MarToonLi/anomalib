{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.transforms.v2 import Resize\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "\n",
    "from anomalib import TaskType\n",
    "import torch\n",
    "\n",
    "import platform\n",
    "\n",
    "def isLinux():\n",
    "    os_name = platform.system()\n",
    "    if os_name.lower() == 'windows': return False\n",
    "    if os_name.lower() == 'linux': return True\n",
    "\n",
    "seed = 67\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "\n",
    "class ExtractBChannel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 可以在这里设置一些参数（如果需要的话），例如大小，填充值等\n",
    "        pass\n",
    "    \n",
    "    # RGB (N, 3, H, W) 的tensor类型\n",
    "    def forward(self, img):\n",
    "        \n",
    "        tmp_img = img.clone()\n",
    "        if len(img.shape) == 3: tmp_img = tmp_img.unsqueeze(0)\n",
    "        bs, channels, height, width = tmp_img.shape\n",
    "        \n",
    "        if channels == 1: tmp_img = tmp_img.repeat(1,3,1,1)\n",
    "        \n",
    "        b_channel = tmp_img[:, 2, :, :]     # 提取 B 通道（张量的第三个通道，索引为2）\n",
    "        b_channel[b_channel < 100/255] = 0\n",
    "        # b_channel[b_channel >= 100/255] = 1    # 不能添加\n",
    "        b_channel_3 = b_channel.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        out_img = b_channel_3\n",
    "        if len(img.shape) == 3: out_img = out_img.squeeze(0)\n",
    "        \n",
    "        print(\"{} --> {} --> {} -- {};\".format(img.shape, tmp_img.shape, b_channel.shape, out_img.shape))\n",
    "        return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from anomalib.callbacks.checkpoint import ModelCheckpoint\n",
    "from anomalib.callbacks import GraphLogger\n",
    "from anomalib.loggers import AnomalibMLFlowLogger\n",
    "from torchvision.transforms.v2 import Resize, RandomHorizontalFlip, Compose, Normalize, ToDtype,RandomAffine,RandomPerspective, Grayscale, ToTensor, Transform, GaussianBlur\n",
    "from anomalib.data.image.folder import Folder, FolderDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read_image,会自动将数据类型转换为float32,但不会进行255归一化\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        ExtractBChannel(),          # 0~1之间\n",
    "        # ToTensor(),\n",
    "        #ToDtype(torch.uint8, scale=True),\n",
    "        Resize((256, 306)),\n",
    "        RandomHorizontalFlip(p=0.3),   # 无seed, 0.90 --> 0.95\n",
    "        #RandomAffine(degrees=(-5, 5), translate=(0.95, 0.95),scale=(0.95, 0.95), ),  # onnx 不支持 grid_sampler.\n",
    "        RandomPerspective(distortion_scale=0.1, p=0.3),\n",
    "        #ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "        Normalize(mean=[0.406, 0.406, 0.406], std=[0.225, 0.225, 0.225]),\n",
    "    ],\n",
    ")\n",
    "\n",
    "eval_transform = Compose(\n",
    "    [\n",
    "        ExtractBChannel(),          # 0~1之间\n",
    "        # ToTensor(),\n",
    "        #ToDtype(torch.uint8, scale=True),\n",
    "        Resize((256, 306)),\n",
    "        #RandomHorizontalFlip(p=0.3),   # 无seed, 0.90 --> 0.95\n",
    "        #RandomAffine(degrees=(-5, 5), translate=(0.95, 0.95),scale=(0.95, 0.95), ),  # onnx 不支持 grid_sampler.\n",
    "        #RandomPerspective(distortion_scale=0.1, p=0.3),\n",
    "        #ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "        Normalize(mean=[0.406, 0.406, 0.406], std=[0.225, 0.225, 0.225]),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pic(inferencer, png_files, input_path, outpath):\n",
    "    from anomalib.data.utils import read_image\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    for file_name in png_files:\n",
    "            \n",
    "        image = read_image(path=os.path.join(input_path, file_name))                     # HWC\n",
    "        CHW_image = read_image(path=os.path.join(input_path, file_name),as_tensor=True)  # CHW\n",
    "        \n",
    "\n",
    "        # 记录开始时间\n",
    "        start_time = time.time()\n",
    "        predictions = inferencer.predict(image=image)\n",
    "        filter_image = ExtractBChannel()(CHW_image)  # CHW -> CHW\n",
    "        filter_image = filter_image.permute(1,2,0)    # CHW -> HWC\n",
    "        \n",
    "        train_image = train_transform(CHW_image)  # CHW -> CHW\n",
    "        train_image = train_image.permute(1,2,0)    # CHW -> HWC\n",
    "        \n",
    "        print(\"image: {}; filter_image: {}; train_image: {}; predictions.heat_map: {};\".format(image.shape, filter_image.shape, train_image.shape, predictions.heat_map.shape))\n",
    "        \n",
    "        \n",
    "        # 记录结束时间\n",
    "        end_time = time.time()\n",
    "\n",
    "        # 计算耗时\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Prediction took {elapsed_time:.4f} seconds.\")\n",
    "        print(predictions.pred_score, predictions.pred_label)\n",
    "        # 创建一个新的图形窗口\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(18, 6))  # 创建一个1行3列的子图网格\n",
    "\n",
    "        # 原始图像\n",
    "        axs[0].imshow(image)\n",
    "        axs[0].set_title('Original Image')\n",
    "        axs[0].axis('off')  # 关闭坐标轴\n",
    "        \n",
    "        # 训练用图像\n",
    "        axs[1].imshow(filter_image.numpy())\n",
    "        axs[1].set_title('Filter Image')\n",
    "        axs[1].axis('off')  # 关闭坐标轴\n",
    "        \n",
    "        # 训练用图像\n",
    "        axs[2].imshow(train_image.numpy())\n",
    "        axs[2].set_title('Train Image')\n",
    "        axs[2].axis('off')  # 关闭坐标轴\n",
    "\n",
    "        # 热图\n",
    "        axs[3].imshow(predictions.heat_map, cmap='hot', interpolation='nearest')\n",
    "        axs[3].set_title('Heat Map')\n",
    "        axs[3].axis('off')  # 关闭坐标轴\n",
    "\n",
    "        # 预测掩模\n",
    "        axs[4].imshow(predictions.pred_mask, cmap='gray', interpolation='nearest')\n",
    "        axs[4].set_title('Predicted Mask')\n",
    "        axs[4].axis('off')  # 关闭坐标轴\n",
    "\n",
    "\n",
    "        # 添加文本信息到图形的上方中间位置\n",
    "        fig_text_x = 0.1  # x坐标在图形宽度的中心位置\n",
    "        fig_text_y = 0.95  # y坐标稍微靠近图形的顶部，避免与子图重叠\n",
    "        fig.text(fig_text_x, fig_text_y,\n",
    "                f'Prediction Time: {elapsed_time:.4f} s\\n'\n",
    "                f'Predicted Class: {predictions.pred_label}\\n'\n",
    "                # f'Score: {predictions.pred_score:.4f}\\n'\n",
    "                f'Threshold: {predictions.pred_score:.4f}' if hasattr(predictions, 'pred_score') else '',\n",
    "                ha='left', va='center', fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.5))  \n",
    "\n",
    "        # 显示整个图形\n",
    "        plt.tight_layout()  # 调整子图间的间距\n",
    "        #plt.show()\n",
    "        plt.savefig(os.path.join(outpath, file_name))\n",
    "        plt.close()\n",
    "        \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "\n",
    "def pplot(imgs, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0])\n",
    "    _, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        for col_idx, img in enumerate(row):\n",
    "            boxes = None\n",
    "            masks = None\n",
    "            if isinstance(img, tuple):\n",
    "                img, target = img\n",
    "                if isinstance(target, dict):\n",
    "                    boxes = target.get(\"boxes\")\n",
    "                    masks = target.get(\"masks\")\n",
    "                elif isinstance(target, tv_tensors.BoundingBoxes):\n",
    "                    boxes = target\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target type: {type(target)}\")\n",
    "            img = F.to_image(img)\n",
    "            if img.dtype.is_floating_point and img.min() < 0:\n",
    "                # Poor man's re-normalization for the colors to be OK-ish. This\n",
    "                # is useful for images coming out of Normalize()\n",
    "                img -= img.min()\n",
    "                img /= img.max()\n",
    "\n",
    "            img = F.to_dtype(img, torch.uint8, scale=True)\n",
    "            if boxes is not None:\n",
    "                img = draw_bounding_boxes(img, boxes, colors=\"yellow\", width=3)\n",
    "            if masks is not None:\n",
    "                img = draw_segmentation_masks(img, masks.to(torch.bool), colors=[\"green\"] * masks.shape[0], alpha=.65)\n",
    "\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(img.permute(1, 2, 0).numpy(), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_root: /local_data/datasets/3-5-jing\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    \"dataset_root\": r\"/local_data/datasets/3-5-jing\" if isLinux() else r\"F:\\Projects\\anomalib\\notebooks\\datasets\\3-5 - jing\",\n",
    "    \"outputs_path\": r\"/local_data/datasets/3-5-jing/outputs\" if isLinux() else r\"F:\\Projects\\anomalib\\notebooks\\datasets\\3-5 - jing\\outputs\",\n",
    "    \"model_name\": \"Patchcore\",\n",
    "}\n",
    "\n",
    "dataset_root = configs[\"dataset_root\"]\n",
    "print(\"dataset_root: {}\".format(dataset_root))\n",
    "\n",
    "normal_folder_path = os.path.join(configs[\"dataset_root\"], \"normal\")\n",
    "abnormal_folder_path = os.path.join(configs[\"dataset_root\"], \"abnormal\")\n",
    "\n",
    "normal_ouput_path = os.path.join(configs[\"outputs_path\"], configs[\"model_name\"] , \"normal_outputs\")\n",
    "abnormal_output_path = os.path.join(configs[\"outputs_path\"], configs[\"model_name\"] , \"abnormal_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom 数据集配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.data.base.datamodule:No normal test images found. Sampling from training set using a split ratio of 0.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "folder_datamodule = Folder(\n",
    "    name=\"3-5\",\n",
    "    root=dataset_root,\n",
    "    normal_dir=\"normal\", abnormal_dir=\"abnormal\",\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    num_workers=0,          # in jupyter, need to be zero. and can be non-0 in python main.py;\n",
    "    # image_size=(256, 256),\n",
    "    train_batch_size = 16, eval_batch_size = 8,                     # 计算的时候会使用cuda，因此需要限制BS不适用默认值32；\n",
    "    train_transform=train_transform, eval_transform=eval_transform,\n",
    "    seed = seed,\n",
    ")\n",
    "\n",
    "folder_datamodule.setup()            #! 进行数据集分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 检查训练集、验证集、测试集的数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "dict_keys(['image_path', 'label', 'image']) torch.Size([16, 3, 256, 306])\n"
     ]
    }
   ],
   "source": [
    "# Train images\n",
    "i, data = next(enumerate(folder_datamodule.train_dataloader()))\n",
    "print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train images\n",
    "# i, data = next(enumerate(folder_datamodule.val_dataloader()))\n",
    "# print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test images\n",
    "# i, data = next(enumerate(folder_datamodule.test_dataloader()))\n",
    "# print(data.keys(), data[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 查看图像内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = to_pil_image(data[\"image\"][0].clone())\n",
    "# Image.fromarray((np.array(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理前的数据:  tensor(0.) tensor(0.9725) tensor(0.0655)\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "tensor(0.) tensor(0.9725) tensor(0.0457)\n",
      "tensor(0.) tensor(0.9362) tensor(0.0655)\n",
      "tensor(0.) tensor(0.9725) tensor(0.0655)\n",
      "tensor(0.) tensor(0.9725) tensor(0.0655)\n",
      "tensor(-1.8044) tensor(2.5180) tensor(-1.5135)\n"
     ]
    }
   ],
   "source": [
    "from anomalib.data.utils import read_image\n",
    "#test_image = read_image(r\"F:\\Projects\\anomalib\\notebooks\\datasets\\3-5\\normal\\1__DA2951175 (2).png\", as_tensor=True)\n",
    "test_image = read_image(r\"/local_data/datasets/3-5-jing/normal/1__DA2951175 (2).png\", as_tensor=True)\n",
    "print(\"处理前的数据: \",test_image.min(), test_image.max(), test_image.mean())\n",
    "\n",
    "\n",
    "\n",
    "for trans in train_transform.transforms:\n",
    "    tmp_image = trans(test_image)\n",
    "    print(tmp_image.min(), tmp_image.max(), tmp_image.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 306])\n",
      "tensor(-1.8044) tensor(1.6501)\n",
      "tensor(-1.8044) tensor(1.9774)\n",
      "tensor(-1.8044) tensor(2.4463)\n",
      "tensor(-1.8044) tensor(2.4919)\n",
      "tensor(-1.8044) tensor(2.4152)\n",
      "tensor(-1.8044) tensor(2.2764)\n",
      "tensor(-1.8044) tensor(1.7671)\n",
      "tensor(-1.8044) tensor(2.4152)\n",
      "tensor(-1.8044) tensor(2.2622)\n",
      "tensor(-1.8044) tensor(2.1572)\n",
      "tensor(-1.8044) tensor(2.4533)\n",
      "tensor(-1.8044) tensor(1.7715)\n",
      "tensor(-1.8044) tensor(2.0561)\n",
      "tensor(-1.8044) tensor(2.1324)\n",
      "tensor(-1.8044) tensor(1.6901)\n",
      "tensor(-1.8044) tensor(2.1258)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_images = []\n",
    "print(data[\"image\"].shape)\n",
    "for i in range(data[\"image\"].shape[0]):\n",
    "    test_img = data[\"image\"][i]\n",
    "    total_images.append(test_img)\n",
    "    print(test_img.min(), test_img.max())\n",
    "\n",
    "pplot(total_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择和优化器配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/wide_resnet50_2.racm_in1k)\n",
      "INFO:timm.models._hub:[timm/wide_resnet50_2.racm_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:anomalib.data.base.datamodule:No normal test images found. Sampling from training set using a split ratio of 0.20\n",
      "WARNING:anomalib.metrics.f1_score:F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                  | Type                     | Params | Mode \n",
      "---------------------------------------------------------------------------\n",
      "0 | model                 | PatchcoreModel           | 24.9 M | train\n",
      "1 | _transform            | Compose                  | 0      | train\n",
      "2 | normalization_metrics | MetricCollection         | 0      | train\n",
      "3 | image_threshold       | F1AdaptiveThreshold      | 0      | train\n",
      "4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train\n",
      "5 | image_metrics         | AnomalibMetricCollection | 0      | train\n",
      "6 | pixel_metrics         | AnomalibMetricCollection | 0      | train\n",
      "---------------------------------------------------------------------------\n",
      "24.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.9 M    Total params\n",
      "99.450    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "174       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdea0204c671484d9b6d65fe7cfebe69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7314cac8f2f41e685af158d3c72a41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.models.image.patchcore.lightning_model:Aggregating the embedding extracted from the training set.\n",
      "INFO:anomalib.models.image.patchcore.lightning_model:Applying core-set subsampling to get the embedding.\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Selecting Coreset Indices.: 100%|██████████| 10233/10233 [00:13<00:00, 741.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:anomalib.callbacks.timer:Training took 48.33 seconds\n",
      "WARNING:anomalib.metrics.f1_score:F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18cb2ae7bbd4a7f9f803ae0d30f4198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.callbacks.timer:Testing took 21.581111431121826 seconds\n",
      "Throughput (batch_size=8) : 1.7144622100714797 FPS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.970370352268219     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9259259104728699     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.970370352268219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9259259104728699    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/projects/results/Patchcore/3-5/latest\n"
     ]
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "from anomalib.models import Padim, Patchcore, Stfpm, Fastflow\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(mode=\"max\", monitor=\"image_F1Score\")\n",
    "early_stopping = EarlyStopping(monitor=\"image_F1Score\", mode=\"max\", patience=3)\n",
    "\n",
    "graph_logger = GraphLogger()\n",
    "callbacks = [\n",
    "    model_checkpoint,\n",
    "    early_stopping,\n",
    "    graph_logger,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if configs[\"model_name\"] == \"Patchcore\":\n",
    "    model = Patchcore()\n",
    "    engine = Engine(task=TaskType.CLASSIFICATION, image_metrics=[\"F1Score\",\"AUROC\"], pixel_metrics=[\"F1Score\",\"AUROC\"], callbacks= callbacks)\n",
    "    engine.train(datamodule=folder_datamodule, model=model)\n",
    "elif configs[\"model_name\"] == \"Fastflow\":\n",
    "    model = Fastflow()\n",
    "    engine = Engine(\n",
    "    pixel_metrics=\"AUROC\",\n",
    "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
    "    logger=False,\n",
    "    task=TaskType.CLASSIFICATION)\n",
    "    engine.train(datamodule=folder_datamodule, model=model, train_dataloaders=folder_datamodule.train_dataloaders, val_dataloaders=folder_datamodule.val_dataloaders, test_dataloaders=folder_datamodule.val_dataloaders)\n",
    "else:\n",
    "    model = Patchcore()\n",
    "    engine = Engine(task=TaskType.CLASSIFICATION)\n",
    "    engine.train(datamodule=folder_datamodule, model=model)\n",
    "    \n",
    "\n",
    "print(engine.trainer.default_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opset_versissssson: 14;\n",
      "torch.Size([1, 3, 1, 1]) --> torch.Size([1, 3, 1, 1]) --> torch.Size([1, 1, 1]) -- torch.Size([1, 3, 1, 1]);\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exported model to F:\\Projects\\anomalib\\notebooks\\100_datamodules\\results\\Patchcore\\3-5\\latest\\weights\\onnx\\model.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save to F:\\Projects\\anomalib\\notebooks\\100_datamodules\\results\\Patchcore\\3-5\\latest).\n"
     ]
    }
   ],
   "source": [
    "# from anomalib.deploy import ExportType\n",
    "# engine.export(model=model, export_type=ExportType.OPENVINO)  # torch.onnx.export op=16\n",
    "# print(f\"Model save to {engine.trainer.default_root_dir}).\") \n",
    "\n",
    "from anomalib.deploy import ExportType\n",
    "engine.export(model=model, export_type=ExportType.ONNX)  # torch.onnx.export op=16\n",
    "print(f\"Model save to {engine.trainer.default_root_dir}).\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "# model_output_path=Path(engine.trainer.default_root_dir)\n",
    "# openvino_model_path = model_output_path / \"weights\" / \"openvino\" / \"model.bin\"\n",
    "# metadata_path = model_output_path / \"weights\" / \"openvino\" / \"metadata.json\"\n",
    "# print(openvino_model_path.exists(), metadata_path.exists())\n",
    "\n",
    "model_output_path=Path(engine.trainer.default_root_dir)\n",
    "openvino_model_path = model_output_path / \"weights\" / \"onnx\" / \"model.onnx\"\n",
    "metadata_path = model_output_path / \"weights\" / \"onnx\" / \"metadata.json\"\n",
    "print(openvino_model_path.exists(), metadata_path.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.deploy import OpenVINOInferencer\n",
    "inferencer = OpenVINOInferencer(\n",
    "    path=openvino_model_path,    # Path to the OpenVINO IR model.\n",
    "    metadata=metadata_path,      # Path to the metadata file.\n",
    "    device=\"AUTO\",               # We would like to run it on an Intel CPU.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11__DA1479053.png', '11__DA2951175.png', '11__DA2951215 (2).png', '11__DA2951215 (3).png', '11__DA2951215 (4).png', '11__DA2951215.png', '11__DA2951225 (2).png', '11__DA2951225.png', '13__DA1479053.png', '13__DA2951175.png', '13__DA2951225.png', '15__DA1479053.png', '15__DA2951175.png', '15__DA2951215 (3).png', '15__DA2951225.png', '17__DA1479053 (2).png', '17__DA1479053.png', '17__DA2951175.png', '17__DA2951215 (2).png', '17__DA2951215 (3).png', '17__DA2951215.png', '17__DA2951225.png', '19__DA1479053 (2).png', '19__DA1479053.png', '19__DA2951175 (2).png', '19__DA2951175 (3).png', '19__DA2951175.png', '19__DA2951215 (2).png', '19__DA2951215 (3).png', '19__DA2951215.png', '19__DA2951225.png', '1__DA2951175 (2).png', '1__DA2951175 (3).png', '1__DA2951175.png', '1__DA2951215 (2).png', '1__DA2951225.png', '3__DA2951175 (2).png', '3__DA2951175 (3).png', '3__DA2951175.png', '3__DA2951215 (2).png', '3__DA2951215.png', '3__DA2951225.png', '53__DA1479053.png', '53__DA2951175.png', '53__DA2951215.png', '53__DA2951225.png', '55__DA1479053.png', '55__DA2951175.png', '55__DA2951215.png', '55__DA2951225.png', '57__DA1479053.png', '57__DA2951215.png', '59__DA1479053.png', '59__DA2951175.png', '59__DA2951215.png', '59__DA2951225.png', '5__DA1479053 (2).png', '5__DA1479053 (3).png', '5__DA1479053.png', '5__DA2951175 (2).png', '5__DA2951175 (3).png', '5__DA2951175.png', '5__DA2951215 (2).png', '5__DA2951215 (3).png', '5__DA2951215.png', '5__DA2951225.png', '61__DA1479053.png', '61__DA2951175.png', '61__DA2951225.png', '63__DA2951175.png', '63__DA2951215.png', '63__DA2951225.png', '65__DA2951175.png', '65__DA2951215.png', '65__DA2951225.png', '67__DA1479053.png', '67__DA2951175.png', '67__DA2951225.png', '69__DA1479053.png', '69__DA2951215 (2).png', '69__DA2951215.png', '71__DA1479053.png', '71__DA2951215.png', '71__DA2951225.png', '73__DA1479053.png', '73__DA2951225.png', '7__DA1479053 (2).png', '7__DA1479053 (3).png', '7__DA1479053.png', '7__DA2951215 (2).png', '7__DA2951215 (3).png', '7__DA2951215.png', '7__DA2951225 (2).png', '7__DA2951225.png', '9__DA1479053 (2).png', '9__DA1479053 (3).png', '9__DA1479053.png', '9__DA2951175 (2).png', '9__DA2951175 (3).png', '9__DA2951175.png', '9__DA2951215 (2).png', '9__DA2951215.png']\n",
      "['11__DA1479053 (2).png', '11__DA1479053 (3).png', '11__DA1479053.png', '11__DA2951175 (2).png', '11__DA2951175 (3).png', '11__DA2951175.png', '11__DA2951225.png', '13__DA1479053 (2).png', '13__DA1479053 (3).png', '13__DA1479053.png', '13__DA2951175 (2).png', '13__DA2951175.png', '13__DA2951215 (2).png', '13__DA2951215 (3).png', '13__DA2951215.png', '13__DA2951225 (2).png', '13__DA2951225.png', '15__DA1479053 (2).png', '15__DA1479053 (3).png', '15__DA1479053.png', '15__DA2951175 (2).png', '15__DA2951175.png', '15__DA2951215 (2).png', '15__DA2951215 - 副本.png', '15__DA2951215.png', '15__DA2951225 (2).png', '15__DA2951225.png', '17__DA1479053 (2).png', '17__DA1479053.png', '17__DA2951175 (2).png', '17__DA2951175.png', '17__DA2951225 (2).png', '17__DA2951225.png', '19__DA1479053.png', '19__DA2951225 (2).png', '19__DA2951225.png', '1__DA1479053 (2).png', '1__DA1479053 (3).png', '1__DA1479053 (4).png', '1__DA1479053.png', '1__DA2951215 (3).png', '1__DA2951215.png', '1__DA2951225 (2).png', '1__DA2951225.png', '3__DA1479053 (2).png', '3__DA1479053 (3).png', '3__DA1479053 (4).png', '3__DA1479053.png', '3__DA2951215.png', '3__DA2951225.png', '57__DA2951175.png', '57__DA2951225.png', '5__DA2951225 (2).png', '5__DA2951225.png', '61__DA2951215.png', '65__DA1479053.png', '67__DA2951215.png', '69__DA1479053.png', '69__DA2951175 (2).png', '69__DA2951175.png', '69__DA2951225 (2).png', '69__DA2951225.png', '71__DA1479053 (2).png', '71__DA2951175 (2).png', '71__DA2951175.png', '71__DA2951215.png', '71__DA2951225.png', '73__DA2951175.png', '73__DA2951215.png', '75__DA1479053.png', '75__DA2951175.png', '75__DA2951215.png', '75__DA2951225.png', '7__DA2951175 (2).png', '7__DA2951175.png', '9__DA1479053.png', '9__DA2951175.png', '9__DA2951215 (3).png', '9__DA2951215.png', '9__DA2951225 (2).png', '9__DA2951225 (3).png', '9__DA2951225 (4).png', '9__DA2951225.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9683758].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4950 seconds.\n",
      "0.5694583725118074 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4585958].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4941 seconds.\n",
      "0.5407965599605364 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9146976].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4808 seconds.\n",
      "0.5989415447200175 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5691 seconds.\n",
      "0.4700477967415926 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.213949].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.0561423].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.8656 seconds.\n",
      "0.5533738539708989 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5229 seconds.\n",
      "0.4700477967415926 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.188545].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6070876].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.7134 seconds.\n",
      "0.6245607212381873 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9192926].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5802 seconds.\n",
      "0.6403223858011913 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.369087].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5315 seconds.\n",
      "0.5826052530452418 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4136682].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5672 seconds.\n",
      "0.6414014135177654 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8913959].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5004 seconds.\n",
      "0.4659918315124278 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.20958].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4595 seconds.\n",
      "0.3583629176020946 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.505027].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4797 seconds.\n",
      "0.3815431326592386 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.0425582].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4855 seconds.\n",
      "0.5869021413275134 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9503675].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5106 seconds.\n",
      "0.6195386716528056 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.395824].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5556 seconds.\n",
      "0.5696673433585802 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9702866].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5783 seconds.\n",
      "0.4572782768909854 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.426336].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4811 seconds.\n",
      "0.44321127533557936 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6117699].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5926 seconds.\n",
      "0.5121215906184221 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5197 seconds.\n",
      "0.5490904642142979 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.690118].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6075436].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5048 seconds.\n",
      "0.5121215906184221 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8702861].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5351 seconds.\n",
      "0.4974735544232362 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.0902944].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5478 seconds.\n",
      "0.4035862677960547 LabelName.NORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5308 seconds.\n",
      "0.5242395930211597 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.150091].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4533346].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4271 seconds.\n",
      "0.45749553480731536 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3798738].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4909 seconds.\n",
      "0.37625918604573677 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4533346].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5898 seconds.\n",
      "0.45749553480731536 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1324186].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5228 seconds.\n",
      "0.46766974951349777 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1324186].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4880 seconds.\n",
      "0.46766974951349777 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8852985].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5027 seconds.\n",
      "0.5802813707872425 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.0627158].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5438 seconds.\n",
      "0.6031580398842133 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3566198].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5170 seconds.\n",
      "0.3659286703730087 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2812362].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5052 seconds.\n",
      "0.43047451931152053 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3496761].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5073 seconds.\n",
      "0.3659286703730087 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6451043].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5034 seconds.\n",
      "0.5642714358723491 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5085 seconds.\n",
      "0.5403063413510589 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.938539].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4826 seconds.\n",
      "0.4245391834007092 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2089615].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1863286].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4791 seconds.\n",
      "0.4964309214657485 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2089615].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5070 seconds.\n",
      "0.4245391834007092 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.7715275].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4808 seconds.\n",
      "0.5730600867220471 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5455 seconds.\n",
      "0.5730600867220471 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.7684001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.5834111].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5649 seconds.\n",
      "0.5631186788668279 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4679348].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5043 seconds.\n",
      "0.5590038498136947 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4949186].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4991 seconds.\n",
      "0.5027642930164267 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1387558].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5279 seconds.\n",
      "0.5107931819117706 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8654592].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5940 seconds.\n",
      "0.6752654553420073 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1567092].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.6508 seconds.\n",
      "0.6111174711759488 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.5792308].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5728 seconds.\n",
      "0.4427208858586882 LabelName.NORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.7191 seconds.\n",
      "0.49753600646288904 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.060364].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.21308].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4581 seconds.\n",
      "0.6278453909625833 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3675303].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4775 seconds.\n",
      "0.43804757666436395 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6227094].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5282 seconds.\n",
      "0.5940717380001097 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.6300 seconds.\n",
      "0.4766959060680315 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1143696].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2437577].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.6046 seconds.\n",
      "0.5251304957154141 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.201116].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5519 seconds.\n",
      "0.4980562977371516 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8120868].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4948 seconds.\n",
      "0.6178515268114039 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8511901].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4983 seconds.\n",
      "0.495030577577992 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2740624].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5438 seconds.\n",
      "0.4615768738473925 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8511901].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4843 seconds.\n",
      "0.495030577577992 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4152074].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4915 seconds.\n",
      "0.5305968005760282 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.276571].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5179 seconds.\n",
      "0.4076061372841069 LabelName.NORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5087 seconds.\n",
      "0.5305968005760282 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4152074].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6061075].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4737 seconds.\n",
      "0.4921768354705714 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6061075].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4629 seconds.\n",
      "0.4921768354705714 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.7508228].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4998 seconds.\n",
      "0.6260696513672555 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.5781757].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5309 seconds.\n",
      "0.4858387650660206 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4060848].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5168 seconds.\n",
      "0.5573471193719051 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3972259].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5787 seconds.\n",
      "0.4910598751881891 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.5816603].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4823 seconds.\n",
      "0.40980212528306326 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4399047].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4962 seconds.\n",
      "0.3780096372638591 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8974422].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5744 seconds.\n",
      "0.4629392851693407 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4930615].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5371 seconds.\n",
      "0.5131357741515535 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.26218].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5428 seconds.\n",
      "0.599559230420004 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.0335283].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5069 seconds.\n",
      "0.44718505333882613 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9932065].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4598 seconds.\n",
      "0.3978288902964567 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2197595].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4631 seconds.\n",
      "0.6294725613418286 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.5507865].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4728 seconds.\n",
      "0.4374775629727581 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.5418283].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5306 seconds.\n",
      "0.5663732759264388 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.2781675].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5206 seconds.\n",
      "0.43502980183993445 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6402082].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5294 seconds.\n",
      "0.607279532766475 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6579477].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5329 seconds.\n",
      "0.4989083280948232 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.492804].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4614 seconds.\n",
      "0.7367778950877498 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9283959].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5207 seconds.\n",
      "0.5125589257634057 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6899053].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5496 seconds.\n",
      "0.45870322568629324 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1519375].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5689 seconds.\n",
      "0.4202715561630082 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.8535749].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.8320 seconds.\n",
      "0.7482855590892835 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5663 seconds.\n",
      "0.5479507785659132 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.7230589].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9804758].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4680 seconds.\n",
      "0.5479507785659132 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.015121].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5104 seconds.\n",
      "0.5160851165768559 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6731476].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5824 seconds.\n",
      "0.4882225363524694 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1027803].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5346 seconds.\n",
      "0.6562232218725326 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.6825031].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4555 seconds.\n",
      "0.4882225363524694 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1258218].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4855 seconds.\n",
      "0.44781299108362577 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.9062054].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5040 seconds.\n",
      "0.5442740535611247 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1245492].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5101 seconds.\n",
      "0.48653504977624057 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.1245492].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.6121 seconds.\n",
      "0.48653504977624057 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.977441].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5261 seconds.\n",
      "0.45663965993283884 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3188798].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5312 seconds.\n",
      "0.49565578144417477 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6016235].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5361 seconds.\n",
      "0.5111345750040452 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5224 seconds.\n",
      "0.49565578144417477 LabelName.NORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.3188798].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.5280223].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5719 seconds.\n",
      "0.7111651260975882 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..1.5920683].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4753 seconds.\n",
      "0.5732257426794847 LabelName.ABNORMAL\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6377466].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5083 seconds.\n",
      "1.0 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6344295].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5129 seconds.\n",
      "0.8046047401012663 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6358032].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4930 seconds.\n",
      "0.8046047401012663 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6376963].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5182 seconds.\n",
      "1.0 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6362193].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4706 seconds.\n",
      "0.8176556785819918 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.634599].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5336 seconds.\n",
      "0.8176556785819918 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6359463].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5348 seconds.\n",
      "0.9885605975301799 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6366212].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5043 seconds.\n",
      "0.9686263507282625 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6366212].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5832 seconds.\n",
      "0.9686263507282625 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6366212].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5102 seconds.\n",
      "0.9686263507282625 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.637303].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5048 seconds.\n",
      "1.0 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.637303].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4544 seconds.\n",
      "1.0 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.566572].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5843 seconds.\n",
      "0.6607154116084929 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.4168751].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4742 seconds.\n",
      "0.8388695514439919 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.566572].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5264 seconds.\n",
      "0.6607154116084929 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.5524433].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5959 seconds.\n",
      "0.7919045924205608 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.5828383].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5153 seconds.\n",
      "0.7919045924205608 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.637362].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4598 seconds.\n",
      "0.839436831256981 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6369026].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5724 seconds.\n",
      "0.839436831256981 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.637362].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5555 seconds.\n",
      "0.839436831256981 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6309273].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5041 seconds.\n",
      "0.6815652514459227 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.604419].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5267 seconds.\n",
      "0.6815652514459227 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5368 seconds.\n",
      "0.7130667949767031 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6344516].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6312215].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.4923 seconds.\n",
      "0.7130667949767031 LabelName.ABNORMAL\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 1.0839 seconds.\n",
      "0.7130667949767031 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6344516].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6362822].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5984 seconds.\n",
      "0.8077757829956509 LabelName.ABNORMAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8044444..2.6362822].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "torch.Size([3, 2048, 2448]) --> torch.Size([1, 3, 2048, 2448]) --> torch.Size([1, 2048, 2448]) -- torch.Size([3, 2048, 2448]);\n",
      "image: (2048, 2448, 3); filter_image: torch.Size([2048, 2448, 3]); train_image: torch.Size([256, 306, 3]); predictions.heat_map: (2048, 2448, 3);\n",
      "Prediction took 0.5308 seconds.\n",
      "0.8077757829956509 LabelName.ABNORMAL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 模型测试\u001b[39;00m\n\u001b[0;32m     19\u001b[0m draw_pic(inferencer, normal_png_files, normal_folder_path, normal_ouput_path)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mdraw_pic\u001b[49m\u001b[43m(\u001b[49m\u001b[43minferencer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabnormal_png_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabnormal_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabnormal_output_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 75\u001b[0m, in \u001b[0;36mdraw_pic\u001b[1;34m(inferencer, png_files, input_path, outpath)\u001b[0m\n\u001b[0;32m     73\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()  \u001b[38;5;66;03m# 调整子图间的间距\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m#plt.show()\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\pyplot.py:1229\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[1;32m-> 1229\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\backend_bases.py:1905\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[1;32m-> 1905\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:387\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    386\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\axes\\_base.py:3137\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3135\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3137\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3140\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:653\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    651\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 653\u001b[0m     im, l, b, trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_magnification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    656\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:952\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    949\u001b[0m transformed_bbox \u001b[38;5;241m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[0;32m    950\u001b[0m clip \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on()\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox)\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmagnification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munsampled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:568\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    565\u001b[0m         output_alpha \u001b[38;5;241m=\u001b[39m _resample(  \u001b[38;5;66;03m# resample alpha channel\u001b[39;00m\n\u001b[0;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m, A[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m], out_shape, t, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[0;32m    567\u001b[0m     output \u001b[38;5;241m=\u001b[39m _resample(  \u001b[38;5;66;03m# resample rgb channels\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[43m_rgb_to_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, out_shape, t, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[0;32m    569\u001b[0m     output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m output_alpha  \u001b[38;5;66;03m# recombine rgb and alpha\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# output is now either a 2D array of normed (int or float) data\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# or an RGBA array of re-sampled input\u001b[39;00m\n",
      "File \u001b[1;32me:\\Appsetup\\Anaconda\\envs\\anoma\\lib\\site-packages\\matplotlib\\image.py:224\u001b[0m, in \u001b[0;36m_rgb_to_rgba\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    222\u001b[0m rgba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m4\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    223\u001b[0m rgba[:, :, :\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m A\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrgba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m:\n\u001b[0;32m    225\u001b[0m     rgba[:, :, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 待测试图像\n",
    "normal_png_files = [f for f in os.listdir(normal_folder_path) if f.endswith('.png')]\n",
    "abnormal_png_files = [f for f in os.listdir(abnormal_folder_path) if f.endswith('.png')]\n",
    "print(normal_png_files)\n",
    "print(abnormal_png_files)\n",
    "\n",
    "\n",
    "import shutil\n",
    "# 输出路径确认\n",
    "if os.path.exists(normal_ouput_path): \n",
    "    shutil.rmtree(normal_ouput_path)\n",
    "if os.path.exists(abnormal_output_path): \n",
    "    shutil.rmtree(abnormal_output_path)\n",
    "os.makedirs(normal_ouput_path)\n",
    "os.makedirs(abnormal_output_path)\n",
    "\n",
    "\n",
    "# 模型测试\n",
    "draw_pic(inferencer, normal_png_files, normal_folder_path, normal_ouput_path)\n",
    "draw_pic(inferencer, abnormal_png_files, abnormal_folder_path, abnormal_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Folder` data module offers much more flexibility cater all different sorts of needs. Please refer to the documentation for more details.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some transforms that will be applied to the images using torchvision. Let's add a transform that resizes the \n",
    "input image to 256x256 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = Resize(image_size, antialias=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_dataset_classification_train \u001b[38;5;241m=\u001b[39m FolderDataset(\n\u001b[0;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 3\u001b[0m     normal_dir\u001b[38;5;241m=\u001b[39m\u001b[43mdataset_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     abnormal_dir\u001b[38;5;241m=\u001b[39mdataset_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m      7\u001b[0m     task\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCLASSIFICATION,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m folder_dataset_classification_train\u001b[38;5;241m.\u001b[39msamples\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "folder_dataset_classification_train = FolderDataset(\n",
    "    name=\"3-5\",\n",
    "    normal_dir=dataset_root / \"normal\",\n",
    "    abnormal_dir=dataset_root / \"abnormal\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_train.samples.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first sample in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_train[0]\n",
    "print(data.keys(), data[\"image\"].shape)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[\"image\"][2])   # RGB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Classification Test Set\n",
    "folder_dataset_classification_test = FolderDataset(\n",
    "    name=\"3-5\",\n",
    "    normal_dir=dataset_root / \"normal\",\n",
    "    abnormal_dir=dataset_root / \"abnormal\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_test.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_test[0]\n",
    "print(data.keys(), data[\"image\"].shape, data[\"image_path\"], data[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
